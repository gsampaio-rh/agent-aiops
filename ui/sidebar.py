"""
Sidebar Components for the Streamlit Ollama Chatbot Application.

This module contains all sidebar-related UI components including:
- Model selection and parameters
- Agent mode toggles
- Session management controls
- Chat statistics display

All components follow Jobs/Ive design principles with minimalist aesthetics.
"""

import streamlit as st
import time
from typing import Dict, Any

from config.settings import (
    APP_TITLE, APP_ICON, DEFAULT_MODEL, MODEL_PARAMS, SHOW_DETAILED_METRICS
)
from services.ollama_service import OllamaService
from services.agent_factory import create_agent, AgentFactory
from utils.chat_utils import (
    clear_chat_history, export_chat_history
)


def render_sidebar() -> Dict[str, Any]:
    """
    Render the sidebar with model selection and parameters.
    
    Returns:
        Dict[str, Any]: Configuration dictionary containing:
            - model: Selected model name
            - params: Model parameters
            - ollama_service: OllamaService instance
            - agent_mode: Whether agent mode is enabled
    """
    try:
        with st.sidebar:
            st.title(f"{APP_ICON} {APP_TITLE}")
            
            # Ollama service health check
            ollama_service = OllamaService()
            if not ollama_service.health_check():
                st.error("‚ùå Ollama service is not running")
                st.info("Please start Ollama: `ollama serve`")
                return {}
            
            st.success("‚úÖ Ollama is running")
            
            # Model selection
            st.subheader("ü§ñ Model")
            available_models = ollama_service.get_available_models()
            
            if not available_models:
                st.error("No models available. Please install a model:")
                st.code(f"ollama pull {DEFAULT_MODEL}")
                return {}
            
            current_model = st.selectbox(
                "Language Model",
                options=available_models,
                index=available_models.index(st.session_state.current_model) 
                      if st.session_state.current_model in available_models 
                      else 0,
                help="Select the language model to use for conversations"
            )
            
            # Update agent if model changed
            if current_model != st.session_state.current_model:
                st.session_state.current_model = current_model
                st.session_state.agent = create_agent(model=current_model)
            
            # Agent type selection (if LangGraph is available)
            if AgentFactory.is_langgraph_available():
                st.subheader("ü§ñ Agent Type")
                available_types = AgentFactory.get_available_agent_types()
                agent_type_labels = {
                    "react": "ReAct Agent (Original)",
                    "langgraph": "LangGraph Agent (Advanced)"
                }
                
                current_agent_type = st.session_state.get("agent_type", "react")
                agent_type = st.radio(
                    "Agent Implementation",
                    options=list(available_types.keys()),
                    format_func=lambda x: agent_type_labels.get(x, x),
                    index=list(available_types.keys()).index(current_agent_type) if current_agent_type in available_types else 0,
                    help="Choose between different agent implementations"
                )
                
                # Update agent if type changed
                if agent_type != st.session_state.get("agent_type"):
                    st.session_state.agent_type = agent_type
                    st.session_state.agent = create_agent(agent_type=agent_type, model=current_model)
                    st.experimental_rerun()
            
            # Agent mode toggle
            st.subheader("üß† Mode")
            agent_mode = st.radio(
                "Chat Mode",
                options=["Normal Chat", "Agent Mode"],
                index=1 if st.session_state.agent_mode else 0,
                help="Normal: Direct chat | Agent: Shows reasoning and can use tools"
            )
            st.session_state.agent_mode = (agent_mode == "Agent Mode")
            
            if st.session_state.agent_mode:
                # Show available tools
                with st.expander("üõ†Ô∏è Available Tools"):
                    if st.session_state.agent and hasattr(st.session_state.agent, 'tools'):
                        for tool_name, tool in st.session_state.agent.tools.items():
                            st.write(f"üì° **{tool_name}**: {tool.description[:80]}...")
                    else:
                        st.write("‚ö†Ô∏è Agent not properly initialized")
                
                # Agent steps visibility toggle  
                st.session_state.show_agent_steps = st.checkbox(
                    "üí≠ Show thinking process",
                    value=st.session_state.show_agent_steps,
                    help="Toggle visibility of the agent's step-by-step reasoning and tool usage"
                )
            
            # Model parameters
            st.subheader("‚öôÔ∏è Parameters")
            
            params = {}
            for param_name, param_config in MODEL_PARAMS.items():
                params[param_name] = st.slider(
                    label=param_name.replace('_', ' ').title(),
                    min_value=param_config["min"],
                    max_value=param_config["max"],
                    value=st.session_state.model_params.get(param_name, param_config["default"]),
                    step=param_config["step"],
                    help=param_config["help"]
                )
            
            st.session_state.model_params = params
            
            # Display settings
            st.subheader("üìä Metrics")
            show_detailed_metrics = st.checkbox(
                "Show detailed metrics",
                value=st.session_state.get("show_detailed_metrics", SHOW_DETAILED_METRICS),
                help="Show comprehensive performance metrics including timing breakdowns and throughput analysis"
            )
            st.session_state.show_detailed_metrics = show_detailed_metrics
            
            # Session management
            st.subheader("üíæ Session")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üóëÔ∏è Clear Chat", use_container_width=True):
                    clear_chat_history()
                    st.session_state.agent_steps = []
                    st.rerun()
            
            with col2:
                if st.button("üì• Export", use_container_width=True):
                    if st.session_state.messages:
                        export_text = export_chat_history()
                        st.download_button(
                            label="Download Chat",
                            data=export_text,
                            file_name=f"chat_export_{int(time.time())}.txt",
                            mime="text/plain"
                        )
            
            # Chat statistics
            if st.session_state.messages:
                st.subheader("üìä Statistics")
                total_messages = len(st.session_state.messages)
                user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
                assistant_messages = total_messages - user_messages
                
                st.metric("Total Messages", total_messages)
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("User", user_messages)
                with col2:
                    st.metric("Assistant", assistant_messages)
            
            return {
                "model": current_model,
                "params": params,
                "ollama_service": ollama_service,
                "agent_mode": st.session_state.agent_mode
            }
    
    except Exception as e:
        st.error(f"Sidebar error: {e}")
        return {}
