# ğŸ¤– Agent-AIOps

A sophisticated AI agent framework featuring LangGraph-based workflow management with a premium Streamlit interface. Built for enterprise-grade AI operations with local Ollama models.

## âœ¨ Key Features

### ğŸ§  **Advanced Agent Architecture**
- **LangGraphAgent**: Workflow management with state machines and checkpointing
- **Tool Integration**: Web search, terminal commands with safety validation
- **Real-time Reasoning**: Step-by-step thought process visualization

### ğŸ”§ **Enterprise Features**
- **Performance Monitoring**: Comprehensive metrics and logging
- **Model Flexibility**: Easy switching between Ollama models
- **Configuration Management**: Environment-based settings with validation

## ğŸš€ Quick Start

### Prerequisites
1. **Install Ollama**: Download from [ollama.ai](https://ollama.ai)
2. **Pull a model**: `ollama pull llama3.2:3b`
3. **Start Ollama**: `ollama serve`

### Installation
```bash
git clone <repository-url>
cd agent-aiops
pip install -r requirements.txt
streamlit run app.py
```

Open your browser to `http://localhost:8501`

## ğŸ—ï¸ Architecture

### Clean, Modular Design
```
agent-aiops/
â”œâ”€â”€ app.py                          # Main application (68 lines)
â”œâ”€â”€ config/                         # Configuration & constants
â”‚   â”œâ”€â”€ settings.py                # Pydantic settings
â”‚   â””â”€â”€ constants.py               # Agent & tool configuration
â”œâ”€â”€ core/                          # Core interfaces & models
â”‚   â”œâ”€â”€ interfaces/               # Service contracts
â”‚   â”‚   â”œâ”€â”€ agent_service.py      # Agent interface
â”‚   â”‚   â”œâ”€â”€ llm_service.py        # LLM interface
â”‚   â”‚   â””â”€â”€ search_service.py     # Search interface
â”‚   â”œâ”€â”€ models/                   # Data models
â”‚   â”‚   â”œâ”€â”€ agent.py             # Agent response models
â”‚   â”‚   â”œâ”€â”€ chat.py              # Chat models
â”‚   â”‚   â””â”€â”€ search.py            # Search models
â”‚   â”œâ”€â”€ exceptions/               # Error handling
â”‚   â””â”€â”€ validators/               # Input validation
â”œâ”€â”€ services/                      # Business logic
â”‚   â”œâ”€â”€ agent_factory.py         # Agent creation & management
â”‚   â”œâ”€â”€ langgraph_agent_service.py # LangGraphAgent implementation
â”‚   â”œâ”€â”€ ollama_service.py        # Ollama LLM integration
â”‚   â”œâ”€â”€ search_service.py        # Multi-provider web search
â”‚   â”œâ”€â”€ mcp_service.py           # Model Context Protocol
â”‚   â””â”€â”€ terminal_tool.py         # Safe terminal execution
â”œâ”€â”€ ui/                           # Modular UI components
â”‚   â”œâ”€â”€ components.py            # Reusable UI components
â”‚   â”œâ”€â”€ styles.py               # Custom CSS styling
â”‚   â”œâ”€â”€ streamlit_utils.py      # Session & utilities
â”‚   â”œâ”€â”€ chat_display.py         # Chat interface
â”‚   â”œâ”€â”€ sidebar.py              # Configuration sidebar
â”‚   â””â”€â”€ tool_execution.py       # Tool execution UI
â””â”€â”€ utils/                        # Utilities
    â”œâ”€â”€ logger.py               # Enterprise logging
    â”œâ”€â”€ chat_utils.py           # Chat utilities
    â””â”€â”€ log_analyzer.py         # Log analysis tools
```

## ğŸ¤– Agent Implementation

### LangGraphAgent
- **Workflow Management**: Graph-based state machines with conditional routing
- **Checkpointing**: Memory persistence across conversations
- **Conditional Logic**: Smart routing between reasoning and tool usage
- **Performance**: ~1.6s average response time
- **Tool Integration**: Seamless web search and terminal execution

## âš™ï¸ Configuration

### Environment Variables
```bash
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama3.2:3b

# Model Parameters
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=1000
DEFAULT_TOP_P=0.9

# Logging
LOG_LEVEL=INFO
LOG_DIR=logs
ENABLE_FILE_LOGGING=true
ENABLE_JSON_LOGGING=true
```

### Agent Configuration (`config/constants.py`)
```python
AGENT_CONFIG = {
    "max_iterations": 10,
    "enable_web_search": True,
    "enable_terminal": True,
    "show_thinking_process": True,
}
```

## ğŸ” Tools & Capabilities

### Built-in Tools
- **Web Search**: DuckDuckGo and SearX providers with fallback
- **Terminal Commands**: Safe execution with security validation
- **Model Context Protocol**: Desktop commander integration

### Tool Safety
- Command validation with allow/deny patterns
- User confirmation for potentially dangerous operations
- Execution timeouts and output size limits
- Comprehensive logging of all tool usage

## ğŸ“Š Monitoring & Logging

### Enterprise-Grade Logging
- **Structured JSON logs** for analysis
- **Correlation IDs** for request tracking
- **Performance metrics** with detailed timing
- **Real-time log viewing** with filtering

### Log Analysis
```bash
# Real-time log viewing
python -m utils.log_analyzer --follow

# Performance analysis
python -m utils.log_analyzer --format json

# Filter by level or module
python -m utils.log_analyzer --level ERROR --module search
```

## ğŸ› ï¸ Development

### Running in Development
```bash
# Install dependencies
pip install -r requirements.txt

# Start with auto-reload
streamlit run app.py --server.runOnSave true

# Run tests
python test_agent.py
```

### Adding New Features
1. **New Tools**: Implement `ToolInterface` in `services/`
2. **UI Components**: Add to `ui/components.py`
3. **Agent Features**: Extend LangGraphAgent workflows
4. **Styling**: Modify `ui/styles.py`

## ğŸ› Troubleshooting

### Common Issues
1. **"Ollama not running"**: Start with `ollama serve`
2. **"No models available"**: Install with `ollama pull llama3.2:3b`
3. **Slow responses**: Try smaller models or reduce max_tokens
4. **LangGraph errors**: Ensure all dependencies are installed

### Performance Optimization
- Use smaller models for faster responses
- Adjust temperature and token limits
- Disable agent mode for simple queries
- Monitor logs for bottlenecks

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ¤ Contributing

Contributions welcome! Please:
- Follow the modular architecture patterns
- Maintain interface contracts
- Add appropriate tests and documentation
- Test the LangGraph agent implementation

---

**Built with â¤ï¸ using enterprise-grade architecture and modern AI patterns.**