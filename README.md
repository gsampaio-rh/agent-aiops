# ğŸ¤– Streamlit Ollama AI Agent Chatbot

A minimalist, high-end AI agent interface built on Streamlit and Ollama, inspired by Dieter Rams' design principles and Apple's user experience philosophy. Features intelligent agent capabilities with web search and real-time reasoning visualization.

## âœ¨ Features

### ğŸ¨ **Premium Interface**
- **Jobs/Ive Aesthetic**: Ultra-minimalist design with Apple-inspired typography and animations
- **Real-time Streaming**: Live response streaming with elegant visual feedback
- **Responsive Design**: Seamless experience across desktop and mobile devices

### ğŸ§  **Intelligent Agent Mode**
- **React Agent Pattern**: Step-by-step reasoning with tool selection and execution
- **Web Search Integration**: Real-time web search with DuckDuckGo and fallback providers
- **Thinking Visualization**: Watch the AI reason through problems in real-time
- **Tool Orchestration**: Intelligent tool selection and result synthesis

### ğŸ“Š **Advanced Analytics**
- **Comprehensive Metrics**: Technical performance data (latency, tokens, throughput)
- **Agent Step Tracking**: Detailed reasoning process with execution times
- **Session Statistics**: Message counts, response times, and usage patterns

### âš™ï¸ **Powerful Configuration**
- **Model Flexibility**: Easy switching between Ollama models with live agent updates
- **Parameter Tuning**: Real-time adjustment of temperature, tokens, and sampling
- **Agent Controls**: Toggle reasoning visibility and tool availability

## ğŸš€ Quick Start

### Prerequisites

1. **Install Ollama**: Download from [ollama.ai](https://ollama.ai)
2. **Pull a model**: 
   ```bash
   ollama pull llama3.2:3b
   ```
3. **Start Ollama service**:
   ```bash
   ollama serve
   ```

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd agent-aiops
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application**:
   ```bash
   streamlit run app.py
   ```

4. **Open your browser** to `http://localhost:8501`

## ğŸ—ï¸ Project Structure

**Clean, modular architecture following enterprise best practices:**

```text
agent-aiops/
â”œâ”€â”€ app.py                      # ğŸ  Main application orchestration (68 lines)
â”œâ”€â”€ requirements.txt            # ğŸ“¦ Python dependencies
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py            # âš™ï¸ Configuration settings
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ollama_service.py      # ğŸ¤– Ollama API integration
â”‚   â”œâ”€â”€ agent_service.py       # ğŸ§  React Agent implementation
â”‚   â””â”€â”€ search_service.py      # ğŸ” Web search providers
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ chat_utils.py          # ğŸ’¬ Chat utility functions
â””â”€â”€ ui/                         # ğŸ¨ Modular UI components
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ styles.py              # ğŸ¨ CSS styling (322 lines)
    â”œâ”€â”€ components.py          # ğŸ§© UI components (332 lines)
    â””â”€â”€ streamlit_utils.py     # âš™ï¸ Session & logic (278 lines)
```

### ğŸ“ˆ **Architecture Benefits**
- **92% reduction** in main app file size (817 â†’ 68 lines)
- **Single responsibility** principle applied throughout
- **Reusable components** for future features
- **Easy testing** and debugging
- **Clean separation** of concerns

## âš™ï¸ Configuration

### Default Settings

- **Model**: `llama3.2:3b`
- **Temperature**: `0.7`
- **Max Tokens**: `1000`
- **Top-p**: `0.9`

### Environment Variables

- `OLLAMA_BASE_URL`: Ollama API URL (default: `http://localhost:11434`)

## ğŸ¨ Design Philosophy

This application follows Dieter Rams' ten principles of good design:

1. **Innovative**: Leveraging modern LLM technology
2. **Useful**: Practical chatbot with real metrics
3. **Aesthetic**: Clean, minimalist interface
4. **Understandable**: Intuitive user experience
5. **Unobtrusive**: Focused on functionality
6. **Honest**: Transparent performance metrics
7. **Long-lasting**: Timeless design principles
8. **Thorough**: Every detail considered
9. **Environmentally friendly**: Efficient resource usage
10. **As little design as possible**: Minimal yet complete

## ğŸ”§ Advanced Usage

### ğŸ¤– **Agent Mode**

Switch to **Agent Mode** in the sidebar to enable intelligent reasoning:

1. **Ask complex questions** that require research or multi-step thinking
2. **Watch the AI reason** through problems step-by-step
3. **See tool selection** and web search in real-time
4. **Toggle thinking visibility** to focus on results when needed

**Example Agent Queries:**
- "What's the latest news about AI developments?"
- "Compare the pros and cons of different programming languages"
- "Research and summarize recent scientific breakthroughs"

### ğŸ” **Web Search Integration**

The agent automatically searches the web when needed:
- **Primary**: DuckDuckGo HTML scraping for comprehensive results
- **Fallback**: Instant Answer API for quick facts
- **Backup**: SearX provider for reliability
- **Manual**: Direct search links as last resort

### ğŸ›ï¸ **Model Management**

1. **Add new models**:
   ```bash
   ollama pull <model-name>
   ```

2. **Live agent updates**: Agent automatically adapts to model changes
3. **Parameter tuning**: Real-time adjustment affects both chat and agent modes

### ğŸ“Š **Metrics & Analytics**

- **Technical Metrics**: Toggle detailed performance data
- **Agent Analytics**: Step execution times and tool usage
- **Session Export**: Download complete chat history with metadata

### ğŸ¨ **UI Customization**

The modular architecture makes customization easy:
- **Styles**: Modify `ui/styles.py` for design changes
- **Components**: Extend `ui/components.py` for new features
- **Logic**: Add functionality in `ui/streamlit_utils.py`

## ğŸ› Troubleshooting

### Common Issues

1. **"Ollama service is not running"**
   - Start Ollama: `ollama serve`
   - Check if port 11434 is available
   - Verify service health in sidebar

2. **"No models available"**
   - Install a model: `ollama pull llama3.2:3b`
   - Verify installation: `ollama list`
   - Restart the application

3. **"Agent not properly initialized"**
   - Ensure Ollama is running and model is selected
   - Check browser console for errors
   - Try switching models in sidebar

4. **Web search not working**
   - Check internet connection
   - DuckDuckGo may be rate-limiting
   - Agent will automatically try fallback providers

5. **Slow responses**
   - Check hardware resources (CPU/RAM)
   - Try a smaller model (e.g., `llama3.2:1b`)
   - Reduce max_tokens parameter
   - Disable agent mode for faster responses

6. **UI components not loading**
   - Clear browser cache
   - Check browser console for JavaScript errors
   - Ensure all UI modules are properly imported

## ğŸ› ï¸ Development

### **Running in Development Mode**

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd agent-aiops
   pip install -r requirements.txt
   ```

2. **Start Ollama service**:
   ```bash
   ollama serve
   ollama pull llama3.2:3b
   ```

3. **Run with hot reload**:
   ```bash
   streamlit run app.py --server.runOnSave true
   ```

### **Code Structure**

The modular architecture makes development easier:
- **`app.py`**: Main orchestration (keep minimal)
- **`ui/`**: All UI components and styling
- **`services/`**: Business logic and API integrations  
- **`utils/`**: Shared utility functions
- **`config/`**: Application configuration

### **Adding New Features**

1. **New UI components**: Add to `ui/components.py`
2. **New agent tools**: Extend `services/agent_service.py`
3. **New styling**: Modify `ui/styles.py`
4. **New utilities**: Add to appropriate `utils/` module

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### **Contribution Guidelines**
- Follow the modular architecture patterns
- Maintain Jobs/Ive design principles
- Add appropriate documentation
- Test both normal and agent modes

## ğŸ“ Support

For support and questions, please open an issue in the repository.

---

**Built with â¤ï¸ using enterprise-grade architecture and Apple-inspired design principles.**
